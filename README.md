# Blur_Attack-Neural-Networks
An adversarial example generator that leverages intensified blurring techniques and noise augmentation to mislead pretrained neural networks. Demonstrated using ResNet18 and ImageNet classes. Witness the balance between human interpretability and machine confusion.
